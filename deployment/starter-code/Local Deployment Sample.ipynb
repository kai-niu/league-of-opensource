{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build toy model and save it to pickle"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 1,
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "accuracy: 0.95\n"
=======
      "accuracy: 0.92\n"
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "\n",
    "iris = load_iris()\n",
    "data, labels = iris.data, iris.target\n",
    "training_data, test_data, training_labels, test_labels = train_test_split(data, labels)\n",
    "\n",
    "model = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "model.fit(training_data, training_labels)\n",
    "accuracy = model.score(test_data, test_labels)\n",
    "print(\"accuracy: {:.2f}\".format(accuracy))\n",
    "\n",
    "# Upload the model\n",
    "\n",
    "pickle.dump(model, open(\"toy_model.pkl\", \"wb\"))\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(\"toy_model.pkl\", \"cortex-ee16ff5ab7\", \"dev/toy_model.pkl\")"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\"lgbm_model.pkl\", \"cortex-ee16ff5ab7\", \"dev/lgbm_model.pkl\")"
   ]
  },
  {
=======
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Predictor Class"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 36,
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
<<<<<<< HEAD
    "labels = [\"True\", \"False\"]\n",
=======
    "labels = [\"setosa\", \"versicolor\", \"virginica\"]\n",
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
    "\n",
    "\n",
    "class PythonPredictor:\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        if os.environ.get(\"AWS_ACCESS_KEY_ID\"):\n",
    "            s3 = boto3.client(\"s3\")  # client will use your credentials if available\n",
    "        else:\n",
    "            s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))  # anonymous client\n",
    "\n",
    "        s3.download_file(config[\"bucket\"], config[\"key\"], \"/tmp/model.pkl\")\n",
    "        \"\"\"\n",
<<<<<<< HEAD
    "        self.model = pickle.load(open(\"lgbm_model.pkl\", \"rb\"))\n",
    "\n",
    "    def predict(self, payload):\n",
    "   \n",
    "        label_id = self.model.predict([payload['data']])[0]\n",
    "        return labels[label_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../assets/dataset/home_db.csv', index_col=None)\n",
    "df.shape\n",
    "df.head()\n",
    "\n",
    "y = df.loc[:,'home_purchase']\n",
    "X = df.loc[:,:'YOUNGEST_DEPENDENT_CHILD_BIRTH_YEAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {'data': list(X_test.loc[0].values)}\n",
    "rf = PythonPredictor(None).model\n",
    "rf.predict([payload['data']])"
=======
    "        self.model = pickle.load(open(\"toy_model.pkl\", \"rb\"))\n",
    "\n",
    "    def predict(self, payload):\n",
    "        measurements = [\n",
    "            payload[\"sepal_length\"],\n",
    "            payload[\"sepal_width\"],\n",
    "            payload[\"petal_length\"],\n",
    "            payload[\"petal_width\"],\n",
    "        ]\n",
    "\n",
    "        label_id = self.model.predict([measurements])[0]\n",
    "        return labels[label_id]"
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Configuration"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 2,
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cortex.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cortex.yaml\n",
<<<<<<< HEAD
    "- name: gamification-model\n",
=======
    "- name: iris-model\n",
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
    "  kind: RealtimeAPI\n",
    "  predictor:\n",
    "    type: python\n",
    "    path: predictor.py\n",
    "    config:\n",
    "      bucket: cortex-ee16ff5ab7\n",
<<<<<<< HEAD
    "      key: dev/lgbm_model.pkl"
=======
    "      key: dev/toy_model.pkl"
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Requirements"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": 3,
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
<<<<<<< HEAD
    "scikit-learn\n",
    "lightgbm"
=======
    "scikit-learn"
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Query Payload"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": [0.0, 55.02699309780146, 325000.0, 1981.0, 676.9948191352805, 0.193144071416786, 1000.0, NaN, 1.0, 3.0, 1000.0, 68387.0, NaN, NaN, 83197.0, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 4650.0, 16249.999999999998, 0.0, 1.0, NaN, NaN, NaN, NaN, 1015.0, NaN, 501.56916060815, 138826.0, 67.0, 84892.0, 119167.0, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 21.0, NaN, NaN]}'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
=======
   "execution_count": 11,
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Overwriting sample.json\n"
=======
      "Writing sample.json\n"
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
     ]
    }
   ],
   "source": [
    "%%writefile sample.json\n",
<<<<<<< HEAD
    "{\"data\": [0.0, 55.02699309780146, 325000.0, 1981.0, 676.9948191352805, 0.193144071416786, 1000.0, NaN, 1.0, 3.0, 1000.0, 68387.0, NaN, NaN, 83197.0, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 4650.0, 16249.999999999998, 0.0, 1.0, NaN, NaN, NaN, NaN, 1015.0, NaN, 501.56916060815, 138826.0, 67.0, 84892.0, 119167.0, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 21.0, NaN, NaN]}"
=======
    "{\n",
    "  \"sepal_length\": 5.2,\n",
    "  \"sepal_width\": 3.6,\n",
    "  \"petal_length\": 1.5,\n",
    "  \"petal_width\": 0.3\n",
    "}"
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model\n",
    "deploy the model in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cortex deploy\n",
    "# !cortex get \n",
    "# !cortex get recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Deployed Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 55,
=======
   "execution_count": 4,
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "True"
=======
      "setosa"
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "!curl https://t0erni03x7.execute-api.us-west-1.amazonaws.com/gamification-model -X POST -H \"Content-Type: application/json\" -d @sample.json"
=======
    "!curl https://t0erni03x7.execute-api.us-west-1.amazonaws.com/iris-model -X POST -H \"Content-Type: application/json\" -d @sample.json"
>>>>>>> f8c9eeb007a6243380737fb73d6f2979ccb5d99d
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
