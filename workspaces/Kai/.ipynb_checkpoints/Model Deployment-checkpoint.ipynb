{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model to aws bucket\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(\"life_allocation.pkl\", \"gamification-ee16ff5ab7\", \"life_allocation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Predictor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "labels = [\"False\", \"True\"]\n",
    "\n",
    "\n",
    "# home purchase model\n",
    "class PythonPredictor:\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        if os.environ.get(\"AWS_ACCESS_KEY_ID\"):\n",
    "            s3 = boto3.client(\"s3\")  # client will use your credentials if available\n",
    "        else:\n",
    "            s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))  # anonymous client\n",
    "\n",
    "        s3.download_file(config[\"bucket\"], config[\"key\"], \"/tmp/model.pkl\")\n",
    "        \"\"\"\n",
    "        self.model = pickle.load(open(\"home_purchase.pkl\", \"rb\"))\n",
    "\n",
    "    def predict(self, payload):\n",
    "   \n",
    "        proba = self.model.predict_proba([payload['data']])[0]\n",
    "        result = [float(val) for val in proba]\n",
    "        return json.dumps({'prob':result, 'label':int(np.argmax(result))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "labels = [\"False\", \"True\"]\n",
    "\n",
    "# life relocation model\n",
    "class PythonPredictor:\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        if os.environ.get(\"AWS_ACCESS_KEY_ID\"):\n",
    "            s3 = boto3.client(\"s3\")  # client will use your credentials if available\n",
    "        else:\n",
    "            s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))  # anonymous client\n",
    "\n",
    "        s3.download_file(config[\"bucket\"], config[\"key\"], \"/tmp/model.pkl\")\n",
    "        \"\"\"\n",
    "        self.model = pickle.load(open(\"life_allocation.pkl\", \"rb\"))\n",
    "\n",
    "    def predict(self, payload):\n",
    "   \n",
    "        proba = self.model.predict_proba([payload['data']])[0]\n",
    "        result = [float(val) for val in proba]\n",
    "        return json.dumps({'prob':result, 'label':int(np.argmax(result))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../../assets/dataset/relocation_db.csv', index_col=None)\n",
    "df.shape\n",
    "df.head()\n",
    "\n",
    "y = df.loc[:,'life_allocation']\n",
    "X = df.loc[:,:'ACNT_SEC_CLOSE_*']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"prob\": [0.6698397851987394, 0.33016021480126057], \"label\": 0}'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test predictor\n",
    "p = {\"data\": [int(val) for val in X_test.iloc[i].values]}\n",
    "rf = PythonPredictor(None)\n",
    "rf.predict(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cortex.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cortex.yaml\n",
    "- name: home-purchase-model\n",
    "  kind: RealtimeAPI\n",
    "  predictor:\n",
    "    type: python\n",
    "    path: predictor.py\n",
    "    config:\n",
    "      bucket: gamification-ee16ff5ab7\n",
    "      key: dev/home_purchase.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cortex.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cortex.yaml\n",
    "- name: life-relocation-model\n",
    "  kind: RealtimeAPI\n",
    "  predictor:\n",
    "    type: python\n",
    "    path: predictor.py\n",
    "    config:\n",
    "      bucket: gamification-ee16ff5ab7\n",
    "      key: dev/life_allocation.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
    "scikit-learn\n",
    "lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model\n",
    "deploy the model in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cortex deploy\n",
    "# !cortex get \n",
    "# !cortex get recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Deployed Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prob': [0.21531037233562156, 0.7846896276643784], 'label': 1}\n",
      "{'prob': [0.21531037233562156, 0.7846896276643784], 'label': 1}\n",
      "{'prob': [0.21531037233562156, 0.7846896276643784], 'label': 1}\n",
      "{'prob': [0.6863351715635667, 0.3136648284364333], 'label': 0}\n",
      "{'prob': [0.7790521441546707, 0.22094785584532922], 'label': 0}\n",
      "{'prob': [0.21531037233562156, 0.7846896276643784], 'label': 1}\n",
      "{'prob': [0.21531037233562156, 0.7846896276643784], 'label': 1}\n",
      "{'prob': [0.30659267244415445, 0.6934073275558456], 'label': 1}\n",
      "{'prob': [0.810935756318447, 0.18906424368155297], 'label': 0}\n",
      "{'prob': [0.5584180618941934, 0.4415819381058066], 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "##\n",
    "# query home purchase model\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../assets/dataset/home_db.csv', index_col=None)\n",
    "y = df.loc[:,'home_purchase']\n",
    "X = df.loc[:,:'ACNT_SEC_CLOSE_*']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# api-endpoint \n",
    "#URL = \"http://localhost:8888\"\n",
    "URL = \"https://rqg11l7hg2.execute-api.us-west-1.amazonaws.com/home-purchase-model\"\n",
    "\n",
    "# send some queries\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "for i in range(10):\n",
    "    p = {\"data\": [int(val) for val in X_test.iloc[i].values]}\n",
    "    r = requests.post(url = URL, data = json.dumps(p), headers=headers)  \n",
    "    print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prob': [0.18250801831122854, 0.8174919816887715], 'label': 1}\n",
      "{'prob': [0.18250801831122854, 0.8174919816887715], 'label': 1}\n",
      "{'prob': [0.18250801831122854, 0.8174919816887715], 'label': 1}\n",
      "{'prob': [0.18250801831122854, 0.8174919816887715], 'label': 1}\n",
      "{'prob': [0.18250801831122854, 0.8174919816887715], 'label': 1}\n",
      "{'prob': [0.18250801831122854, 0.8174919816887715], 'label': 1}\n",
      "{'prob': [0.18250801831122854, 0.8174919816887715], 'label': 1}\n",
      "{'prob': [0.18250801831122854, 0.8174919816887715], 'label': 1}\n",
      "{'prob': [0.6698397851987394, 0.33016021480126057], 'label': 0}\n",
      "{'prob': [0.6698397851987394, 0.33016021480126057], 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "##\n",
    "# query life relocation model\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../assets/dataset/relocation_db.csv', index_col=None)\n",
    "df.shape\n",
    "df.head()\n",
    "\n",
    "y = df.loc[:,'life_allocation']\n",
    "X = df.loc[:,:'ACNT_SEC_CLOSE_*']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# api-endpoint \n",
    "URL = \"https://rqg11l7hg2.execute-api.us-west-1.amazonaws.com/life-relocation-model\"\n",
    "\n",
    "# send some queries\n",
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "for i in range(10):\n",
    "    p = {\"data\": [int(val) for val in X_test.iloc[i].values]}\n",
    "    r = requests.post(url = URL, data = json.dumps(p), headers=headers)  \n",
    "    print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [1968, 4, 2, 0, 0, 0, 1, 0, 1, 0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sample.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile sample.json\n",
    "{\"data\": [1968, 4, 2, 0, 0, 0, 1, 0, 1, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:8888 -X POST -H \"Content-Type: application/json\" -d @sample.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "!curl https://t0erni03x7.execute-api.us-west-1.amazonaws.com/gamification-model -X POST -H \"Content-Type: application/json\" -d @sample.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
